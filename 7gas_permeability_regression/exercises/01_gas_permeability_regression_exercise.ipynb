{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edex 2: Estimate gas permeability through polymer membranes from chemical structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement and Motivations\n",
    "In this edex, we'll be testing a few regression models to link chemical structure to a property.\n",
    "\n",
    "#### Goal: \n",
    "Estimate the ideal single-gas permeability through a polymer membrane using the chemical structure of the repeating unit. A database of empirical data from ~300 papers is provided in accompanying excel spreadsheet \"Perm_Data.xlsx\"\n",
    "\n",
    "#### Motivation: \n",
    "This is another opportunity to study a structure-property relationship, though it requires a different tool than last time. Since we want our model output to be a continuous numerical value, we will use regression. A successful regression model here enables fast prediction of an otherwise arduous lab experiment, as well as easy screening of cutting-edge materials for gas separations. \n",
    "\n",
    "#### Relevant Materials Science Background:\n",
    "- As climate change mounts in intensity, climate-friendly methods for chemical separations grow increasingly necessary. Membrane-based separations require far less energy than distillation, but are less understood in comparison. Testing different formulations takes time and effort, thus a high-throughput tool to screen materials for desired gas separation capabilities is highly valuable. \n",
    "- Polymers are made up of repeating units of atoms, which in this case are subtly different from \"monomers\". Whereas monomers are the compounds that undergo reaction to yield the eventual polymer, repeat units are the actual structures that constitute the polymer chain. \n",
    "- Studies in the literature have found success in group contribution methods. These involve empirically calculating moiety-specific contributions to the overall compound's permeability over several cases, such that any polymer's permeability could be estimated as a sum of of its parts. For more information, see the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Papers:\n",
    "\n",
    "Background:\\\n",
    "[1]\tPark, Ho Bum, et al. “Maximizing the Right Stuff: The Trade-off between Membrane Permeability and Selectivity.” Science, vol. 356, June 2017.\n",
    "\n",
    "ML Context:\\\n",
    "[2]\tBarnett, J. Wesley, et al. “Designing Exceptional Gas-Separation Polymer Membranes Using Machine Learning.” Science Advances, vol. 6, no. 20, 2020, doi:10.1126/sciadv.aaz4301.\n",
    "\n",
    "Group Contribution Theory:\\\n",
    "[3]\tRobeson, L. “A Group Contribution Approach to Predict Permeability and Permselectivity of Aromatic Polymers.” Journal of Membrane Science, vol. 132, no. 1, 1997, pp. 33–54., doi:10.1016/s0376-7388(97)00031-8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framing the Problem in ML\n",
    "\n",
    "This problem explores the other half of supervised learning. Regression maps an input variable to a prediction. This can be as simple as lines of best fit, but ML versions can get far more sophisticated. In order to use regression for our purposes here, we will need to vectorize a chemical structure to construct a numerical input for our model. \n",
    "\n",
    "In this example, we implement the fingerprinting methods from the RDKit python module to encode chemical structures on several size scales. The result is a vector of a prescribed length with binary values. Topological fingerprints will have 2,048 bits, or indices in the vector, while MACCS keys will have 167. These will form an input matrix of size NxM, where N is the number of polymers and M is the length of the fingerprint vector. Our output will be an array of size Nx1, containing permeability predictions for each polymer. The number of polymers will vary by gas due to data availability in the literature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "Begin by importing the necessarypython packages. If any are not installed, check their documentation for installation guides using either pip or conda. \n",
    "\n",
    "For additional models, you will need to import additional libraries of your own choosing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, MACCSkeys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Import the data from \"Perm_Data.xlsx\".\n",
    "\n",
    "Make sure your excel file is in the same folder as this notebook file so you can directly import it. This file contains gas permeabilities for a few hundred polymers, as well as the chemical information stored in SMILES strings (more on this below). \n",
    "\n",
    "Note that the master dataframe has several blank columns and NaN (not a number) entries. The NaNs are due to certain papers having data avilable for only a few gases out of the six studied here. To proceed, we will need to clean the data up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Perm_Data.xlsx')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 0: Polymer names\\\n",
    "Column 1: SMILES string format\\\n",
    "Columns 2-7: Permeability values for each gas\\\n",
    "Columns 8-9: Experimental operating temperature and pressure\n",
    "\n",
    "SMILES is a text-based format which encodes the atoms present in a molecule (here the molecules are the repeating units of the polymer, capped on either end with hydrogens) and how they're connected. This is one of the easiest ways to get the computer to understand what molecule you're looking at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split name and strings into gas-specific datasets\n",
    "He_data = data.loc[:,[\"Polymer\", \"SMILES\", \"He\"]]\n",
    "H2_data = data.loc[:,[\"Polymer\", \"SMILES\", \"H2\"]]\n",
    "CO2_data = data.loc[:,[\"Polymer\", \"SMILES\", \"CO2\"]]\n",
    "O2_data = data.loc[:,[\"Polymer\", \"SMILES\", \"O2\"]]\n",
    "N2_data = data.loc[:,[\"Polymer\", \"SMILES\", \"N2\"]]\n",
    "CH4_data = data.loc[:,[\"Polymer\", \"SMILES\", \"CH4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CH4_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataframes with helper function\n",
    "\n",
    "Create a function which takes a pandas dataframe as an input, cleans it, and returns it. Your function should drop all rows where at least one element is missing (since not knowing the polymer's name, structure, or permeability would make that point useless), as well as drop all duplicate entries for the same polymer. Across multiple papers, some polymers are repeated, so you might consider dropping duplicates by subsetting the SMILES column. Once your function is written, apply it to each gas-specific dataset and preview the final dataframe to check for correctness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='RED'>YOUR SOLUTION:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    \n",
    "    #gets rid of NaN (not a number) entries in the dataframes\n",
    "\n",
    "\n",
    "    # Drop duplicate SMILES rows (repeated entries from separate papers)\n",
    "  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "He_data = clean_df(He_data)\n",
    "\n",
    "H2_data = clean_df(H2_data)\n",
    "\n",
    "CO2_data = clean_df(CO2_data)\n",
    "\n",
    "O2_data = clean_df(O2_data)\n",
    "\n",
    "N2_data = clean_df(N2_data)\n",
    "\n",
    "CH4_data = clean_df(CH4_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview cleaned data as a safety check\n",
    "O2_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize entries in the dataframe\n",
    "To get the molecule in a usable format, we have to create a mol object. This is most easily done using the SMILES strings from the second column in the above dataframes. RDKit has a function in the Chem module called \"MolFromSmiles\" to do this. The mol object's methods will report some useful information in a convenient way, as well as enable the vectorization of the molecule for regression purposes.\n",
    "\n",
    "First, use Chem.MolFromSmiles() to get a mol object out of a SMILES string (which you can get from any dataframe above using the [Gas]_data.iloc[] function). Whatever variable you store your mol object in, simply type the name of the variable again in a new line to show the image of the molecule. In the following cell, use the mol.GetAtoms() method and loop over each atom in the resulting list to print each atom's atomic number in the molecule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='RED'>YOUR SOLUTION:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mol object from the SMILES string in row 0, column 1 (polyaniline)\n",
    "mol = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='RED'>YOUR SOLUTION:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print atomic number of each atom in the mol object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate fingerprints from mol objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to make a fixed-length vector format for each polymer for regression operations to go smoothly. The helper function `calculate_fingerprint` below will calculate a 2,048-bit binary vector for any input mol object. This vector, specifically the Daylight-like topological fingerprint, encodes chemical structures fragment by fragment. For more information, see the link below:\n",
    "\n",
    "https://rdkit.org/UGM/2012/Landrum_RDKit_UGM.Fingerprints.Final.pptx.pdf \\\n",
    "\n",
    "There are several methods of calculating the fingerprint, such as morgan fingerprints, MACCS keys, etc. While rdkfingerprint and morgan are the most common, they may present instances of bit collision, where multiple chemical patterns map to the same index of the vector. For this reason, we also consider using MACCS keys to trade some index-level molecular detail for robust index-level detail. The function `get_MACCS` below calculates the MACCS key vector for a given mol object. MACCS keys are always fixed, so no bit collisions will occur. The MACCS key descriptors are located at the following link:\n",
    "\n",
    "https://github.com/rdkit/rdkit/blob/master/rdkit/Chem/MACCSkeys.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fingerprint(mol):\n",
    "    fps = [] # Initialize empty array to store fingerprint\n",
    "    arr = np.zeros((1,)) # Zero vector to create fingerprint\n",
    "    # Defaults are minPath=1,maxPath=7,fpSize=2048,bitsPerHash=2,useHs=True,tgtDensity=0.0 defaults   \n",
    "    fp_temp = Chem.RDKFingerprint(mol, minSize=128) # Calculate fingerprint\n",
    "    DataStructs.ConvertToNumpyArray(fp_temp, arr) # Swap fingerprint values into zero array\n",
    "    fps.append(arr) # Store fingerprint into array\n",
    "    \n",
    "    return fps\n",
    "\n",
    "def get_MACCS(mol):\n",
    "    fp = MACCSkeys.GenMACCSKeys(mol) # Generate MACCS key vector\n",
    "    fp = fp.ToBitString()\n",
    "    fp = np.fromiter(fp, float) # This line here is just to save a headache or two\n",
    "    return fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the functions in the cells below by creating first a topological fingerprint, then a MACCS key vector. Print the length of each fingerprint to ensure they contain the correct number of bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='RED'>YOUR SOLUTION:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function on mol example from above\n",
    "\n",
    "\n",
    "# Print the length of the fingerprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='RED'>YOUR SOLUTION:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of MACCS keys, test on mol from above and print length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an array of fingerprints for one gas\n",
    "Input the name of the dataframe you want to work with in the cell below to switch between gas-specific datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a deep copy to avoid overwriting the original dataframe since python does that sometimes\n",
    "ML_data = O2_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will create an N x 2048 array of 1's and 0's. Each row is one polymer in your dataset. The cell prints the index of the polymer it's on so you can see which polymers, if any, cause issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start array with the 0th (first) molecule in the dataframe\n",
    "\n",
    "mol_init = Chem.MolFromSmiles(ML_data.iloc[0,1])\n",
    "fp = calculate_fingerprint(mol_init)\n",
    "\n",
    "# Create database of fingerprints by stacking subsequent fingerprints\n",
    "for i in range(1, len(ML_data)):\n",
    "    try:\n",
    "        mol_temp = Chem.MolFromSmiles(ML_data.iloc[i,1])\n",
    "        fp_temp = calculate_fingerprint(mol_temp)\n",
    "    except:\n",
    "        print(\"Error getting fingerprint\")\n",
    "    fp = np.vstack([fp, fp_temp])\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set data up for model training\n",
    "\n",
    "Regression operations generally take the form below, where X is an array of data, w is a vector of learned parameters, and y is a vector of target values (permeability for this case). This equation can be read as minimizing the gap between the model prediction (matrix multiplication Xw) and actual values (y) by changing w, penalizing the square of deviations. The second term is scaled by a generic hyperparameter $\\lambda$, with the blank placeholder allowing for variations like Ridge regression. "
   ]
  },
  {
   "attachments": {
    "regression.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![regression.jpg](attachment:regression.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we prepare the X matrix and y vector for use in generic scikitlearn regression models. Keep an eye on the size of each component and make sure they match, as this can save you from mistakes. These are matrix operations, so problems will stand out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fp))\n",
    "print('--------------------------------------------------')\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure the gas noted below matches your dataframe selection above from the 'Create an array of fingerprints for one gas' section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perms = ML_data['O2'].values\n",
    "print(len(perms))\n",
    "print('--------------------------------------------------')\n",
    "print(perms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the permeability values are quite varied. Typically they are handled in base-10 logarithm forms in membranes research. This shrinks the range of the data, making it more tractable for model fitting as well. Now we'll split the dataset into a training set and a testing set, taking the log of the y data so we don't have to worry about that later. Ratios may vary, but somewhere around 80/20 is generally safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fp, np.log10(perms), train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Linear Regression\n",
    "Most scikitlearn models have the same flow. You start by initializing the model, often times setting the random state option (you'll see this in plenty of other models as you start to use more) to some routine value (any integer you like) just for good practice. This makes sure any random shuffles are exactly the same on later trials for reproducability.\n",
    "\n",
    "Next, you fit the model to your data, usually with `[model].fit(X_train, y_train)`, but recall that our `y_train` is actually `np.log10(y_train)`, so model predictions will also be in $log_{10}$ form. To evaluate performance, there are a few options. You can start by checking the $R^{2}$ value, the coefficient of determination. This number tells you how much of your data's variance is captured by the model. Always check both training scores and testing scores. If training scores are significantly higher than testing, you may have overfit the model to the training data, in which case the model may generalize poorly to outside data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training score: ' + str(linreg.score(X_train, y_train)))\n",
    "print('Testing score: ' + str(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the model's performance looks on a more detailed level, we can try parity plots and/or getting a histogram of deviations between model prediction and actual values. First, we'll need to run model predictions on our testing set fingerprints $X_{test}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X_test)\n",
    "print(len(y_pred))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A parity plot is just a scatter of $y_{pred}$ versus $y_{test}$. These should ideally form a line along the y=x diagonal, meaning that every prediction is more or less spot-on with the actual value in the test set, but you will have some fluctuations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(y_test, y_pred, color='blue')\n",
    "plt.xlabel('$y_{test}$')\n",
    "plt.ylabel('$y_{pred}$')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_test - y_pred\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(errors, bins=20, color='blue',  density=True)\n",
    "plt.xlabel('Error [$log_{10}$ space]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Linear Model Errors');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quite a few data points are off by huge margins (remember the log scale). Why might this be happening? What can we do about this? Evidently, linear models won't suffice here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a few other models\n",
    "\n",
    "For ideas on what types exist, check out scikit learn's website here:\n",
    "https://scikit-learn.org/stable/user_guide.html\n",
    "\n",
    "Regression falls under supervised learning, so feel free to explore that whole area. Searching \"regression\" in the top right corner of the page will bring up more options than initially displayed on that page (such as sklearn.neural_network.MLPRegressor). Note that most pages will have a working code example if you scroll down in case you're having difficulty getting one to work. See which types of models give better performance and consider why that might be the case. Other models can be found in different python packages if you're feeling adventurous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='RED'>YOUR SOLUTION:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='RED'>YOUR SOLUTION:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='RED'>YOUR SOLUTION:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity plot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "5eb283eee3b05d3474a0f21cbfcf88097eebf509725afef1563d51b60fb338bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
